{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>length_width_ratio</th>\n",
       "      <th>major_axis_length</th>\n",
       "      <th>minor_axis_length</th>\n",
       "      <th>convex_area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89673</td>\n",
       "      <td>260</td>\n",
       "      <td>459</td>\n",
       "      <td>0.566449</td>\n",
       "      <td>455.995692</td>\n",
       "      <td>254.486127</td>\n",
       "      <td>92794</td>\n",
       "      <td>182549.6827</td>\n",
       "      <td>193.282660</td>\n",
       "      <td>204.596936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015058</td>\n",
       "      <td>0.009503</td>\n",
       "      <td>0.032839</td>\n",
       "      <td>0.054997</td>\n",
       "      <td>0.056311</td>\n",
       "      <td>0.024992</td>\n",
       "      <td>0.018933</td>\n",
       "      <td>0.756933</td>\n",
       "      <td>0.022592</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77242</td>\n",
       "      <td>306</td>\n",
       "      <td>386</td>\n",
       "      <td>0.792746</td>\n",
       "      <td>419.518438</td>\n",
       "      <td>235.842058</td>\n",
       "      <td>80317</td>\n",
       "      <td>155983.7209</td>\n",
       "      <td>171.472010</td>\n",
       "      <td>187.837951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>0.029842</td>\n",
       "      <td>0.047219</td>\n",
       "      <td>0.055489</td>\n",
       "      <td>0.022267</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.789869</td>\n",
       "      <td>0.016433</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91228</td>\n",
       "      <td>368</td>\n",
       "      <td>410</td>\n",
       "      <td>0.897561</td>\n",
       "      <td>490.239529</td>\n",
       "      <td>239.819880</td>\n",
       "      <td>93077</td>\n",
       "      <td>183450.9039</td>\n",
       "      <td>191.164193</td>\n",
       "      <td>194.322412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.011358</td>\n",
       "      <td>0.037514</td>\n",
       "      <td>0.063042</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.025261</td>\n",
       "      <td>0.016306</td>\n",
       "      <td>0.743939</td>\n",
       "      <td>0.022367</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93910</td>\n",
       "      <td>300</td>\n",
       "      <td>456</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>485.497337</td>\n",
       "      <td>249.129221</td>\n",
       "      <td>94954</td>\n",
       "      <td>187818.1997</td>\n",
       "      <td>184.290374</td>\n",
       "      <td>199.038196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014108</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.036328</td>\n",
       "      <td>0.060631</td>\n",
       "      <td>0.060633</td>\n",
       "      <td>0.025722</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>0.745097</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72568</td>\n",
       "      <td>228</td>\n",
       "      <td>414</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>417.270300</td>\n",
       "      <td>228.515450</td>\n",
       "      <td>75303</td>\n",
       "      <td>148327.5060</td>\n",
       "      <td>216.744088</td>\n",
       "      <td>231.689395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>0.016697</td>\n",
       "      <td>0.030242</td>\n",
       "      <td>0.041675</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>0.862417</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  length  width  length_width_ratio  major_axis_length  \\\n",
       "0  89673     260    459            0.566449         455.995692   \n",
       "1  77242     306    386            0.792746         419.518438   \n",
       "2  91228     368    410            0.897561         490.239529   \n",
       "3  93910     300    456            0.657895         485.497337   \n",
       "4  72568     228    414            0.550725         417.270300   \n",
       "\n",
       "   minor_axis_length  convex_area    perimeter      r_mean      g_mean  ...  \\\n",
       "0         254.486127        92794  182549.6827  193.282660  204.596936  ...   \n",
       "1         235.842058        80317  155983.7209  171.472010  187.837951  ...   \n",
       "2         239.819880        93077  183450.9039  191.164193  194.322412  ...   \n",
       "3         249.129221        94954  187818.1997  184.290374  199.038196  ...   \n",
       "4         228.515450        75303  148327.5060  216.744088  231.689395  ...   \n",
       "\n",
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.015058  0.009503  0.032839  0.054997  0.056311  0.024992  0.018933   \n",
       "1  0.010692  0.006278  0.029842  0.047219  0.055489  0.022267  0.016508   \n",
       "2  0.013833  0.011358  0.037514  0.063042  0.058600  0.025261  0.016306   \n",
       "3  0.014108  0.010272  0.036328  0.060631  0.060633  0.025722  0.018108   \n",
       "4  0.007658  0.003603  0.016697  0.030242  0.041675  0.011364  0.011147   \n",
       "\n",
       "          8         9              class  \n",
       "0  0.756933  0.022592  Kirmizi_Pistachio  \n",
       "1  0.789869  0.016433  Kirmizi_Pistachio  \n",
       "2  0.743939  0.022367  Kirmizi_Pistachio  \n",
       "3  0.745097  0.021761  Kirmizi_Pistachio  \n",
       "4  0.862417  0.011100  Kirmizi_Pistachio  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\PROJECTWORSHOP\\Soybean_Seeds\\Csv data\\hat_cuoi_basic_glcm_lbp.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit_transform(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_scaler = le.fit_transform(y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaler, y_scaler, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracies = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for KNN: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "Best score for KNN: 0.9480974529346623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       372\n",
      "           1       0.97      0.92      0.94       273\n",
      "\n",
      "    accuracy                           0.95       645\n",
      "   macro avg       0.95      0.95      0.95       645\n",
      "weighted avg       0.95      0.95      0.95       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search_knn = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for KNN:\", grid_search_knn.best_params_)\n",
    "print(\"Best score for KNN:\", grid_search_knn.best_score_)\n",
    "\n",
    "y_pred_knn = grid_search_knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best score for SVM: 0.9713820598006645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       372\n",
      "           1       0.96      0.96      0.96       273\n",
      "\n",
      "    accuracy                           0.97       645\n",
      "   macro avg       0.97      0.97      0.97       645\n",
      "weighted avg       0.97      0.97      0.97       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "grid_search_svm = GridSearchCV(svm, param_grid_svm, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)\n",
    "print(\"Best score for SVM:\", grid_search_svm.best_score_)\n",
    "\n",
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'bootstrap': False, 'criterion': 'entropy', 'n_estimators': 300, 'random_state': 0}\n",
      "Best score for Random Forest: 0.956093023255814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       372\n",
      "           1       0.94      0.92      0.93       273\n",
      "\n",
      "    accuracy                           0.94       645\n",
      "   macro avg       0.94      0.94      0.94       645\n",
      "weighted avg       0.94      0.94      0.94       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'bootstrap': [True, False],\n",
    "\t'random_state' : [0,2,4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "print(\"Best score for Random Forest:\", grid_search_rf.best_score_)\n",
    "\n",
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score for Logistic Regression: 0.9680575858250278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       372\n",
      "           1       0.95      0.97      0.96       273\n",
      "\n",
      "    accuracy                           0.96       645\n",
      "   macro avg       0.96      0.96      0.96       645\n",
      "weighted avg       0.96      0.96      0.96       645\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "420 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1204, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\baohu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [       nan 0.90551495 0.91482835 0.94345293 0.93811739 0.9441196\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90551495 0.91815504 0.94345293 0.93811739 0.9441196\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90551495 0.91815504 0.94345293 0.93811739 0.9441196\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96073976 0.95874862 0.95941085 0.95873976 0.95675083\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96073976 0.96141085 0.95941085 0.95873976 0.96074197\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96073976 0.9607464  0.95941085 0.95873976 0.96074197\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96805094 0.96073976 0.96739535 0.96805759 0.95874419\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96805094 0.96672868 0.96739535 0.96805759 0.96672868\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96805094 0.96539313 0.96739535 0.96805759 0.96739313\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96472868 0.95941085 0.96605537 0.96605537 0.9587464\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96472868 0.96672647 0.96605537 0.96605537 0.96672647\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96472868 0.96539313 0.96605537 0.96605537 0.96539313\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "grid_search_lr = GridSearchCV(lr, param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Logistic Regression:\", grid_search_lr.best_params_)\n",
    "print(\"Best score for Logistic Regression:\", grid_search_lr.best_score_)\n",
    "\n",
    "y_pred_lr = grid_search_lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for XGBoost: {'learning_rate': 0.1, 'n_estimators': 300, 'subsample': 0.6}\n",
      "Best score for XGBoost: 0.9700598006644519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       372\n",
      "           1       0.97      0.95      0.96       273\n",
      "\n",
      "    accuracy                           0.97       645\n",
      "   macro avg       0.97      0.97      0.97       645\n",
      "weighted avg       0.97      0.97      0.97       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.6, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=5, scoring='accuracy')\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for XGBoost:\", grid_search_xgb.best_params_)\n",
    "print(\"Best score for XGBoost:\", grid_search_xgb.best_score_)\n",
    "\n",
    "y_pred_xgb = grid_search_xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for CatBoost: {'depth': 4, 'iterations': 500, 'learning_rate': 0.3}\n",
      "Best score for CatBoost: 0.9700575858250277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       372\n",
      "           1       0.96      0.95      0.95       273\n",
      "\n",
      "    accuracy                           0.96       645\n",
      "   macro avg       0.96      0.96      0.96       645\n",
      "weighted avg       0.96      0.96      0.96       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_catboost = {\n",
    "    'iterations': [100, 300, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'depth': [4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "catboost_model = CatBoostClassifier(verbose=0, random_state=42)\n",
    "grid_search_catboost = GridSearchCV(catboost_model, param_grid_catboost, cv=5, scoring='accuracy')\n",
    "grid_search_catboost.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for CatBoost:\", grid_search_catboost.best_params_)\n",
    "print(\"Best score for CatBoost:\", grid_search_catboost.best_score_)\n",
    "\n",
    "y_pred_catboost = grid_search_catboost.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_catboost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Extra Trees: {'bootstrap': False, 'max_depth': None, 'n_estimators': 500}\n",
      "Best score for Extra Trees: 0.9507663344407529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       372\n",
      "           1       0.93      0.93      0.93       273\n",
      "\n",
      "    accuracy                           0.94       645\n",
      "   macro avg       0.94      0.94      0.94       645\n",
      "weighted avg       0.94      0.94      0.94       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_et = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 30, 50],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "et = ExtraTreesClassifier(random_state=42)\n",
    "grid_search_et = GridSearchCV(et, param_grid_et, cv=5, scoring='accuracy')\n",
    "grid_search_et.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Extra Trees:\", grid_search_et.best_params_)\n",
    "print(\"Best score for Extra Trees:\", grid_search_et.best_score_)\n",
    "\n",
    "y_pred_et = grid_search_et.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_et))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Decision Tree: {'criterion': 'entropy', 'random_state': 0, 'splitter': 'best'}\n",
      "Best score for Decision Tree: 0.9234795127353266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       372\n",
      "           1       0.89      0.93      0.91       273\n",
      "\n",
      "    accuracy                           0.92       645\n",
      "   macro avg       0.92      0.92      0.92       645\n",
      "weighted avg       0.92      0.92      0.92       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_dt = {\n",
    "    'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter' : ['best', 'random'],\n",
    "    'random_state' : [0,1,2,3,4]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "grid_search_dt = GridSearchCV(dt, param_grid_dt, cv=5, scoring='accuracy')\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Decision Tree:\", grid_search_dt.best_params_)\n",
    "print(\"Best score for Decision Tree:\", grid_search_dt.best_score_)\n",
    "\n",
    "y_pred_dt = grid_search_dt.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Gaussian Naive Bayes: {'var_smoothing': 1e-09}\n",
      "Best score for Gaussian Naive Bayes: 0.8310033222591363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88       372\n",
      "           1       0.82      0.85      0.84       273\n",
      "\n",
      "    accuracy                           0.86       645\n",
      "   macro avg       0.86      0.86      0.86       645\n",
      "weighted avg       0.86      0.86      0.86       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_gnb = {\n",
    "    'var_smoothing': [1e-09, 1e-05]\n",
    "}\n",
    "\n",
    "gnb = GaussianNB()\n",
    "grid_search_gnb = GridSearchCV(gnb, param_grid_gnb, cv=5, scoring='accuracy')\n",
    "grid_search_gnb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Gaussian Naive Bayes:\", grid_search_gnb.best_params_)\n",
    "print(\"Best score for Gaussian Naive Bayes:\", grid_search_gnb.best_score_)\n",
    "\n",
    "y_pred_gnb = grid_search_gnb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MLPClassifier: {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Best score for MLPClassifier: 0.9740509413067553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       372\n",
      "           1       0.96      0.97      0.97       273\n",
      "\n",
      "    accuracy                           0.97       645\n",
      "   macro avg       0.97      0.97      0.97       645\n",
      "weighted avg       0.97      0.97      0.97       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150, ), (200, )],\n",
    "    'activation': ['tanh', 'relu', 'logistic', 'identity'],\n",
    "    'solver': ['adam'],\n",
    "    'learning_rate': ['constant', 'adaptive', 'invscaling']\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(random_state=42, max_iter=1000)\n",
    "grid_search_mlp = GridSearchCV(mlp, param_grid_mlp, cv=5, scoring='accuracy')\n",
    "grid_search_mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for MLPClassifier:\", grid_search_mlp.best_params_)\n",
    "print(\"Best score for MLPClassifier:\", grid_search_mlp.best_score_)\n",
    "\n",
    "y_pred_mlp = grid_search_mlp.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, accuracy in model_accuracies.items():\n",
    "    print(f\"{model} Accuracy score: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
